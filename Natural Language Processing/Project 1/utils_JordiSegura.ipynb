{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Question pairs\n",
    "\n",
    "\n",
    "This notebook contains the functions built by *Jordi Segura*.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:25:17.783857Z",
     "start_time": "2022-03-09T15:25:15.968878Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodie\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import os\n",
    "import re # To do ReGeX\n",
    "# !pip install spacy\n",
    "import spacy # For NER\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz # To compute similiraties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:25:21.204584Z",
     "start_time": "2022-03-09T15:25:20.241473Z"
    }
   },
   "outputs": [],
   "source": [
    "path_data =  os.path.expanduser('~') \n",
    "\n",
    "# use this to train and VALIDATE your solution\n",
    "train_df = pd.read_csv(\"./quora_train_data.csv\")\n",
    "\n",
    "# use this to provide the expected generalization results\n",
    "test_df = pd.read_csv(\"./quora_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:25:21.395094Z",
     "start_time": "2022-03-09T15:25:21.376139Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346692</td>\n",
       "      <td>38482</td>\n",
       "      <td>10706</td>\n",
       "      <td>Why do I get easily bored with everything?</td>\n",
       "      <td>Why do I get bored with things so quickly and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327668</td>\n",
       "      <td>454117</td>\n",
       "      <td>345117</td>\n",
       "      <td>How do I study for Honeywell company recruitment?</td>\n",
       "      <td>How do I study for Honeywell company recruitme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272993</td>\n",
       "      <td>391373</td>\n",
       "      <td>391374</td>\n",
       "      <td>Which search engine algorithm is Quora using?</td>\n",
       "      <td>Why is Quora not using reliable search engine?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54070</td>\n",
       "      <td>82673</td>\n",
       "      <td>95496</td>\n",
       "      <td>How can I smartly cut myself?</td>\n",
       "      <td>Can someone who thinks about suicide for 7 yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46450</td>\n",
       "      <td>38384</td>\n",
       "      <td>72436</td>\n",
       "      <td>How do I see who is viewing my Instagram videos?</td>\n",
       "      <td>Can one tell who viewed my Instagram videos?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  346692   38482   10706         Why do I get easily bored with everything?   \n",
       "1  327668  454117  345117  How do I study for Honeywell company recruitment?   \n",
       "2  272993  391373  391374      Which search engine algorithm is Quora using?   \n",
       "3   54070   82673   95496                      How can I smartly cut myself?   \n",
       "4   46450   38384   72436   How do I see who is viewing my Instagram videos?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Why do I get bored with things so quickly and ...             1  \n",
       "1  How do I study for Honeywell company recruitme...             1  \n",
       "2     Why is Quora not using reliable search engine?             0  \n",
       "3  Can someone who thinks about suicide for 7 yea...             0  \n",
       "4       Can one tell who viewed my Instagram videos?             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "Text normalization refers to the process of transforming raw text data into a standardized form, which can include tasks such as converting all text to lowercase, replacing contractions with their expanded form, and replacing common abbreviations or acronyms with their full form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['question1', 'question2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER - Name Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose these entity types because they are commonly relevant to the types of questions and answers in the Quora competition.\n",
    "\n",
    "- PERSON: Refers to names of people, which may be important in questions and answers that involve people or personalities.\n",
    "- GPE (Geo-Political Entity): Refers to names of countries, cities, and other geopolitical entities, which may be important in questions and answers that involve locations or politics.\n",
    "- LOC (Location): Refers to other location names, which may be important in questions and answers that involve places or travel.\n",
    "- DATE: Refers to dates, which may be important in questions and answers that involve historical events, schedules, or timeframes.\n",
    "- TIME: Refers to times, which may be important in questions and answers that involve schedules or specific moments.\n",
    "- MONEY: Refers to monetary values, which may be important in questions and answers that involve finance or pricing.\n",
    "- ORG: Refers to names of organizations or companies, which may be important in questions and answers that involve business or industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_entities(text):\n",
    "    \"\"\"\n",
    "    Masks named entities of types PERSON, GPE, LOC, DATE, TIME, MONEY, and ORG with their respective entity labels.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be masked.\n",
    "\n",
    "    Returns:\n",
    "    str: The text with named entities masked.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['PERSON', 'GPE', 'LOC', 'DATE', 'TIME', 'MONEY', 'ORG']:\n",
    "            text = text.replace(ent.text, f'<{ent.label_}>')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From:=>\n",
      "  Is the Pulsar 200 NS officially discontinued? <-TO-> Is the <ORG> 200 <GPE> officially discontinued?\n"
     ]
    }
   ],
   "source": [
    "print(f\"From:=>\\n  {train_df.loc[305]['question2']} <-TO-> {mask_entities(train_df.loc[305]['question2'])}\") # ojo. va millor sense fer lower segurament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question1_ner'] = train_df['question1'].apply(lambda x: mask_entities(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question2_ner'] = train_df['question2'].apply(lambda x: mask_entities(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions and abreviations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of common contractions and their expanded form\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# Dictionary of common abbreviations and their full form\n",
    "abbreviations_dict = {\n",
    "    \"aka\": \"also known as\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"etc\": \"et cetera\",\n",
    "    \"e.g.\": \"for example\",\n",
    "    \"i.e.\": \"that is\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"wtf\": \"what the fuck\"\n",
    "}\n",
    "\n",
    "def normalize_text(text, contractions_dict, abbreviations_dict):\n",
    "    try:\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Expand contractions\n",
    "        for contraction, expansion in contractions_dict.items():\n",
    "            text = re.sub(r\"\\b\" + contraction + r\"\\b\", expansion, text)\n",
    "\n",
    "        # Replace abbreviations\n",
    "        for abbreviation, full_form in abbreviations_dict.items():\n",
    "            text = re.sub(r\"\\b\" + abbreviation + r\"\\b\", full_form, text)\n",
    "\n",
    "        return text\n",
    "    except:\n",
    "        # NANs\n",
    "        print(text)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From:=>\n",
      " What's the best thing to ever happen to you? <-TO-> what is the best thing to ever happen to you?\n"
     ]
    }
   ],
   "source": [
    "print(f\"From:=>\\n {train_df['question1'][71]} <-TO-> {normalize_text(train_df['question1'][71], contractions_dict, abbreviations_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question1_norm'] = train_df['question1_ner'].apply(lambda x: normalize_text(x, contractions_dict, abbreviations_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question2_norm'] = train_df['question2_ner'].apply(lambda x: normalize_text(x, contractions_dict, abbreviations_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word_equal(row):\n",
    "    \"\"\"Computes whether the first word of the two questions are equal.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        A binary value indicating whether the first word of the two questions are equal.\n",
    "    \"\"\"\n",
    "    q1_words = row['question1'].split()\n",
    "    q2_words = row['question2'].split()\n",
    "    return int(q1_words[0] == q2_words[0])\n",
    "\n",
    "def last_word_equal(row):\n",
    "    \"\"\"Computes whether the last word of the two questions are equal.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        A binary value indicating whether the last word of the two questions are equal.\n",
    "    \"\"\"\n",
    "    q1_words = row['question1'].split()\n",
    "    q2_words = row['question2'].split()\n",
    "    return int(q1_words[-1] == q2_words[-1])\n",
    "\n",
    "def common_words_count(row):\n",
    "    \"\"\"Computes the number of common words between the two questions.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        An integer value indicating the number of common words between the two questions.\n",
    "    \"\"\"\n",
    "    q1_words = row['question1'].split()\n",
    "    q2_words = row['question2'].split()\n",
    "    common_words = set(q1_words).intersection(set(q2_words))\n",
    "    return len(common_words)\n",
    "\n",
    "def common_words_ratio(row):\n",
    "    \"\"\"Computes the ratio of common words between the two questions to the total number of words in both questions.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        A float value indicating the ratio of common words between the two questions to the total number of words in both questions.\n",
    "    \"\"\"\n",
    "    q1_words = row['question1'].split()\n",
    "    q2_words = row['question2'].split()\n",
    "    common_words = set(q1_words).intersection(set(q2_words))\n",
    "    return len(common_words) / (len(q1_words) + len(q2_words))\n",
    "\n",
    "def fuzz_ratio(row):\n",
    "    \"\"\"Computes the fuzzy string matching ratio between the two questions.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        An integer value indicating the fuzzy string matching ratio between the two questions.\n",
    "    \"\"\"\n",
    "    return fuzz.ratio(row['question1'], row['question2'])\n",
    "\n",
    "def longest_substring_ratio(row):\n",
    "    \"\"\"Computes the ratio of the length of the longest common substring between the two questions to the length of the shorter question.\n",
    "\n",
    "    Args:\n",
    "        row: A pandas Series containing the 'question1' and 'question2' columns.\n",
    "\n",
    "    Returns:\n",
    "        A float value indicating the ratio of the length of the longest common substring between the two questions to the length of the shorter question.\n",
    "    \"\"\"\n",
    "    # Extract the values of 'question1' and 'question2' from the input row\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    # If q1 is longer than q2, swap their values\n",
    "    if len(q1) > len(q2):\n",
    "        q1, q2 = q2, q1\n",
    "    # Compute the length of q1 and create an empty list to store the substring scores\n",
    "    len_q1 = len(q1)\n",
    "    substr_scores = []\n",
    "    # Iterate over all possible substrings of q1\n",
    "    for i in range(len_q1):\n",
    "        for j in range(i+1, len_q1+1):\n",
    "            # Extract the substring from q1 and compute its ratio score with q2\n",
    "            substr = q1[i:j]\n",
    "            substr_scores.append(fuzz.ratio(substr, q2) / len(substr))\n",
    "    # Return the maximum score in the list of substring scores\n",
    "    return max(substr_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the extra features and add them to the dataframe\n",
    "df['first_word_equal'] = df.apply(first_word_equal, axis=1)\n",
    "df['last_word_equal'] = df.apply(last_word_equal, axis=1)\n",
    "df['common_words_count'] = df.apply(common_words_count, axis=1)\n",
    "df['common_words_ratio'] = df.apply(common_words_ratio, axis=1)\n",
    "\n",
    "# EXPENSIVE\n",
    "df['fuzz_ratio'] = df.apply(fuzz_ratio, axis=1)\n",
    "df['longest_substring_ratio'] = df.apply(longest_substring_ratio, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
