{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reproduce results\n",
    "\n",
    "<div style=\"color:red; font-size:14px;\">!! Don't define functions here, import them from utils.py</div>\n",
    "\n",
    "This notebook loads the trained models from disk and shows the results obtained with them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "home_dir = os.environ['HOME']\n",
    "path_folder_quora = home_dir + '/Datasets/QuoraQuestionPairs'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(path_folder_quora, 'quora_train_data.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 20px;background-color: #2cbc84; color: white; margin-bottom: 15px; font-size:20px\">\n",
    "Simple Solution Evaluation\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/simple_solution/lr_model.pkl', 'rb') as file:\n",
    "    lr_model = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "    X_train = scipy.sparse.csr_matrix(X_train)\n",
    "with open('model_artifacts/simple_solution/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "    X_val = scipy.sparse.csr_matrix(X_val)\n",
    "with open('model_artifacts/simple_solution/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "    X_test = scipy.sparse.csr_matrix(X_test)\n",
    "with open('model_artifacts/simple_solution/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/qid_df.pkl', 'rb') as file:\n",
    "    qid_df = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(lr_model, X_train, y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(lr_model, X_val, y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(lr_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 20px;background-color: #2cbc84; color: white; margin-bottom: 15px; font-size:20px\">\n",
    "Improved Solution Evaluation\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Baseline model\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution_baseline/xgb_model.pkl', 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('model_artifacts/qid_df.pkl', 'rb') as file:\n",
    "    qid_df = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(xgb_model, X_train.drop(['qid1','qid2','id'], axis = 1), y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(xgb_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(xgb_model, X_test.drop(['qid1','qid2','id'], axis = 1), y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(xgb_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val.iloc[i,1]\n",
    "    qid2 = X_val.iloc[i, 2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Baseline model with CountVectorizer features\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('model_artifacts/improved_solution_baseline_cv/xgb_model.pkl', 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_cv/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('model_artifacts/qid_df.pkl', 'rb') as file:\n",
    "    qid_df = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(xgb_model, X_train[:, 3:], y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(xgb_model, X_val[:, 3:], y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(xgb_model, X_test[:, 3:], y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(xgb_model, X_val[:, 3:], y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val[i, 1]\n",
    "    qid2 = X_val[i, 2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Baseline model with TF-IDF features\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('model_artifacts/improved_solution_baseline_tf/xgb_model.pkl', 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_baseline_tf/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('model_artifacts/qid_df.pkl', 'rb') as file:\n",
    "    qid_df = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(xgb_model, X_train[:, 3:], y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(xgb_model, X_val[:, 3:], y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(xgb_model, X_test[:, 3:], y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(xgb_model, X_val[:, 3:], y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val[i, 1]\n",
    "    qid2 = X_val[i, 2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Model with feature selection + XGBoost\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution_topfeatures/xgb_model.pkl', 'rb') as file:\n",
    "    xgb_model_improve = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution_topfeatures/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('model_artifacts/qid_df.pkl', 'rb') as file:\n",
    "    qid_df = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(xgb_model_improve, X_train.drop(['qid1','qid2','id'], axis = 1), y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(xgb_model_improve, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(xgb_model_improve, X_test.drop(['qid1','qid2','id'], axis = 1), y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(xgb_model_improve, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val.iloc[i,-3]\n",
    "    qid2 = X_val.iloc[i, -2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Model with feature selection + Random Forest\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution_topfeatures/rf_model.pkl', 'rb') as file:\n",
    "    rf_model = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(rf_model, X_train.drop(['qid1','qid2','id'], axis = 1), y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(rf_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(rf_model, X_test.drop(['qid1','qid2','id'], axis = 1), y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(rf_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val.iloc[i,-3]\n",
    "    qid2 = X_val.iloc[i, -2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Model with feature selection + Histogram-Based Gradient Boosting\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution_topfeatures/hbgd_model.pkl', 'rb') as file:\n",
    "    hbgd_model = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(hbgd_model, X_train.drop(['qid1','qid2','id'], axis = 1), y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(hbgd_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(hbgd_model, X_test.drop(['qid1','qid2','id'], axis = 1), y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(hbgd_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val.iloc[i,-3]\n",
    "    qid2 = X_val.iloc[i, -2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert\" style=\"padding: 10px;background-color: #6bd0a9; color: white; margin-bottom: 15px; font-size:17px\">\n",
    "Model with feature selection + Ensemble model\n",
    "<p>Combination of XGBoost and HistGradientBoostingClassifier</p>\n",
    "</div>\n",
    "\n",
    "#### Load files related to the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution_topfeatures/eclf1.pkl', 'rb') as file:\n",
    "    ensembling_model = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(ensembling_model, X_train.drop(['qid1','qid2','id'], axis = 1), y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(ensembling_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(ensembling_model, X_test.drop(['qid1','qid2','id'], axis = 1), y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(ensembling_model, X_val.drop(['qid1','qid2','id'], axis = 1), y_val)\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_val.iloc[i,-3]\n",
    "    qid2 = X_val.iloc[i, -2]\n",
    "    print('Original question 1: {}'.format(train_df[train_df['qid1']==qid1].question1.values[0]))\n",
    "    print('Original question 2: {}'.format(train_df[train_df['qid2']==qid2].question2.values[0]))\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values[0]))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values[0]))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_val[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
